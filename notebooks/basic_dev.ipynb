{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c294cdf",
   "metadata": {},
   "source": [
    "# Stochastic Parameters Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee138be",
   "metadata": {},
   "source": [
    "## Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8161c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fredapi import Fred\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize FRED (get a free API key from FRED)\n",
    "fred = Fred(api_key=API_KEY)\n",
    "\n",
    "# PPI: Hot Rolled Steel Bars, Plates, and Structural Shapes\n",
    "P = fred.get_series(\"WPU101704\").to_frame(name=\"P_steel_ppi\")\n",
    "\n",
    "# PPI: Iron and Steel Scrap\n",
    "C = fred.get_series(\"WPU1012\").to_frame(name=\"C_scrap_ppi\")\n",
    "\n",
    "# IPG3311A2S: Industrial Production Index: Steel Products\n",
    "D = fred.get_series(\"IPG3311A2S\").to_frame(name=\"D_steel_ip\")\n",
    "\n",
    "P.index = pd.to_datetime(P.index)\n",
    "C.index = pd.to_datetime(C.index)\n",
    "D.index = pd.to_datetime(D.index)\n",
    "\n",
    "P = P.resample(\"MS\").mean()\n",
    "C = C.resample(\"MS\").mean()\n",
    "D = D.resample(\"MS\").mean()\n",
    "\n",
    "data = pd.concat([P, C, D], axis=1).dropna()\n",
    "\n",
    "data.plot(title=\"Finished Steel Product Price vs. Scrap Price vs. Steel Industrial Production\", ylabel=\"Index (1982=100)\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule of thumb for number of data points\n",
    "# ~ 10 * k^2 * p\n",
    "# k = number of variables\n",
    "# p = number of lags in VAR\n",
    "\n",
    "k = 3 \n",
    "p = 2\n",
    "n_data_points = 10 * k**2 * p\n",
    "\n",
    "data = data[-n_data_points:]\n",
    "data.plot(title=\"Finished Steel Product Price vs. Scrap Price vs. Steel Industrial Production\", ylabel=\"Index (1982=100)\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c96360",
   "metadata": {},
   "source": [
    "## VAR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc24a6",
   "metadata": {},
   "source": [
    "Δlog Returns & Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab33268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Δlog(x_t) = log(x_t) - log(x_{t-1})  ~ monthly % change\n",
    "Δlog = np.log(data[[\"D_steel_ip\", \"P_steel_ppi\", \"C_scrap_ppi\"]]).diff().dropna()\n",
    "\n",
    "Δlog.plot(title=\"Log-Returns of Steel Demand, Price, and Scrap Cost\")\n",
    "Δlog.hist(bins=30, figsize=(10, 6))\n",
    "\n",
    "# NOTE: Volatility Ranking\n",
    "# It is usually expected to have: std(Δlog D) << std(Δlog P) < std(Δlog C)\n",
    "# However since the dataset are index data which are smoothed, we may not see this pattern clearly\n",
    "\n",
    "# NOTE: Kurtosis and Skewness\n",
    "# Heavier tails (kurtosis > 3) may be observed due to economic shocks of 2008 and COVID-19 in 2020\n",
    "print(Δlog.agg([\"mean\", \"std\", \"skew\", \"kurtosis\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2f5ce",
   "metadata": {},
   "source": [
    "Order Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit VAR model\n",
    "model = VAR(Δlog)\n",
    "\n",
    "# Pick lag via BIC/AIC (recommended)\n",
    "lag_sel = model.select_order(maxlags=12)   # monthly -> try up to 12\n",
    "\n",
    "# NOTE: EXPECTED LAG ORDER IS SMALL\n",
    "# It is expected for steel markets to have p = 1 or 2 months\n",
    "# since production reacts fast to price changes\n",
    "p = lag_sel.selected_orders[\"bic\"]\n",
    "print(\"Selected lag order (BIC):\", p)\n",
    "lag_sel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f486c",
   "metadata": {},
   "source": [
    "Model Fit & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit VAR(p)\n",
    "var_res = model.fit(p)\n",
    "\n",
    "# Check Correlation of Residuals\n",
    "# NOTE: EXPECTED BEHAVIOR\n",
    "# 1. Price vs Demand: low correlation is expected since price changes should not instantaneously affect demand\n",
    "# 2. Cost vs Price: cost partially affects immediate price changes and some are delayed\n",
    "# 3. Cost vs Demand: higher demand lead to higher scrap prices due to higher steel production \n",
    "# (*) some may differ since index data are considered\n",
    "print(\"Residual Correlation Matrix:\")\n",
    "print(var_res.resid.corr())\n",
    "\n",
    "\n",
    "# Impulse Response Functions\n",
    "# NOTE: Orthogonalized vs Non-Orthogonalized\n",
    "# Orthogonalized IRF assumes shocks are uncorrelated (Cholesky decomposition)\n",
    "# Non-Orthogonalized IRF allows correlated shocks (more realistic in economics)\n",
    "from matplotlib import pyplot as plt\n",
    "irf = var_res.irf(12)  # 12-month horizon\n",
    "irf.plot(orth=False)\n",
    "plt.show()\n",
    "irf.plot_cum_effects(orth=False)\n",
    "plt.show()\n",
    "\n",
    "# Simulate Future Scenarios\n",
    "import numpy as np\n",
    "S, T = 5000, 24\n",
    "\n",
    "sim_list = []\n",
    "for _ in range(S):\n",
    "    path = var_res.simulate_var(steps=T)\n",
    "    sim_list.append(path)\n",
    "\n",
    "sim = np.array(sim_list)\n",
    "\n",
    "print(f\"Simulation shape: {sim.shape}\")  # Should be (5000, 24, 3)\n",
    "\n",
    "hist_corr = Δlog.corr()\n",
    "sim_flat = sim.reshape(-1, sim.shape[2])\n",
    "sim_corr = pd.DataFrame(sim_flat, columns=Δlog.columns).corr()\n",
    "\n",
    "print(\"\\nHistorical correlation:\\n\", hist_corr)\n",
    "print(\"\\nSimulated correlation:\\n\", sim_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9905bd9",
   "metadata": {},
   "source": [
    "## Scenario Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a49b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Settings\n",
    "# -----------------------------\n",
    "HORIZON_MONTHS = 12\n",
    "N_SCENARIOS = 50_000\n",
    "SEED = 42\n",
    "\n",
    "# Anchors (Option 2) - pick a month where you know (or assume) real prices\n",
    "t0 = data.index.max()     # must exist in df.index\n",
    "P0_real = 800.0       # €/ton (example finished steel price at t0)\n",
    "C0_real = 400.0       # €/ton (example scrap price at t0)\n",
    "\n",
    "# Demand scaling (optional):\n",
    "# If you want demand in tons instead of an index, set one anchor:\n",
    "D0_real = 50_0000.0    # tons at t0 (example)\n",
    "use_demand_scaling_to_tons = True  # set True if you want tons\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def simulate_var_returns(var_res, steps: int, n_scenarios: int, seed: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulates VAR returns using Gaussian innovations with covariance sigma_u.\n",
    "    Output shape: (S, T, k)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    k = var_res.neqs\n",
    "    Sigma = var_res.sigma_u.values\n",
    "    chol = np.linalg.cholesky(Sigma)\n",
    "\n",
    "    # last p observations of endogenous returns\n",
    "    p = var_res.k_ar\n",
    "    y_hist0 = var_res.endog[-p:].copy()\n",
    "\n",
    "    sims = np.zeros((n_scenarios, steps, k))\n",
    "    for s in range(n_scenarios):\n",
    "        y_hist = y_hist0.copy()\n",
    "        for t in range(steps):\n",
    "            eps = chol @ rng.standard_normal(k)\n",
    "            yhat = var_res.forecast(y_hist, steps=1)[0]\n",
    "            ynew = yhat + eps\n",
    "            sims[s, t, :] = ynew\n",
    "\n",
    "            if p > 1:\n",
    "                y_hist = np.vstack([y_hist[1:], ynew])\n",
    "            else:\n",
    "                y_hist = np.array([ynew])\n",
    "    return sims\n",
    "\n",
    "def reconstruct_from_returns(last_level: float, returns: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given last observed level and a sequence of Δlog returns,\n",
    "    reconstruct levels: level_t = last_level * exp(cumsum(returns))\n",
    "    returns: shape (T,)\n",
    "    \"\"\"\n",
    "    return last_level * np.exp(np.cumsum(returns))\n",
    "\n",
    "def anchor_index_to_real(ppi_path: np.ndarray, ppi_t0: float, real_t0: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert index path to real €/ton via anchoring:\n",
    "    price_t = real_t0 * (ppi_t / ppi_t0)\n",
    "    \"\"\"\n",
    "    return real_t0 * (ppi_path / ppi_t0)\n",
    "\n",
    "# -----------------------------\n",
    "# Columns order (must match VAR endog order)\n",
    "# -----------------------------\n",
    "cols = [\"D_steel_ip\", \"P_steel_ppi\", \"C_scrap_ppi\"]\n",
    "\n",
    "# Returns data used for VAR\n",
    "df_ret = np.log(data[cols]).diff().dropna()\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Simulate return scenarios from VAR(2)\n",
    "# -----------------------------\n",
    "sim_ret = simulate_var_returns(var_res, steps=HORIZON_MONTHS, n_scenarios=N_SCENARIOS, seed=SEED)\n",
    "# sim_ret shape: (S, T, k)\n",
    "\n",
    "# Map indices\n",
    "k_names = list(df_ret.columns)\n",
    "iD = k_names.index(\"D_steel_ip\")\n",
    "iP = k_names.index(\"P_steel_ppi\")\n",
    "iC = k_names.index(\"C_scrap_ppi\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Decide simulation start date + last observed levels\n",
    "# -----------------------------\n",
    "start_date = (data.index.max() + pd.offsets.MonthBegin(1)).normalize()\n",
    "dates = pd.date_range(start=start_date, periods=HORIZON_MONTHS, freq=\"MS\")\n",
    "\n",
    "last_date = data.index.max()\n",
    "D_last = float(data.loc[last_date, \"D_steel_ip\"])\n",
    "P_last = float(data.loc[last_date, \"P_steel_ppi\"])\n",
    "C_last = float(data.loc[last_date, \"C_scrap_ppi\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Reconstruct index level paths from Δlog returns\n",
    "# -----------------------------\n",
    "D_paths_idx = np.zeros((HORIZON_MONTHS, N_SCENARIOS))\n",
    "P_paths_ppi = np.zeros((HORIZON_MONTHS, N_SCENARIOS))\n",
    "C_paths_ppi = np.zeros((HORIZON_MONTHS, N_SCENARIOS))\n",
    "\n",
    "for s in range(N_SCENARIOS):\n",
    "    D_paths_idx[:, s] = reconstruct_from_returns(D_last, sim_ret[s, :, iD])\n",
    "    P_paths_ppi[:, s] = reconstruct_from_returns(P_last, sim_ret[s, :, iP])\n",
    "    C_paths_ppi[:, s] = reconstruct_from_returns(C_last, sim_ret[s, :, iC])\n",
    "\n",
    "D_paths_idx = pd.DataFrame(D_paths_idx, index=dates, columns=[f\"s{s}\" for s in range(N_SCENARIOS)])\n",
    "P_paths_ppi = pd.DataFrame(P_paths_ppi, index=dates, columns=[f\"s{s}\" for s in range(N_SCENARIOS)])\n",
    "C_paths_ppi = pd.DataFrame(C_paths_ppi, index=dates, columns=[f\"s{s}\" for s in range(N_SCENARIOS)])\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Anchor PPIs to real €/ton (Option 2)\n",
    "# -----------------------------\n",
    "t0_ts = pd.Timestamp(t0)\n",
    "if t0_ts not in data.index:\n",
    "    raise ValueError(f\"t0={t0} not found in data.index. Choose a YYYY-MM-01 that exists.\")\n",
    "\n",
    "P_ppi_t0 = float(data.loc[t0_ts, \"P_steel_ppi\"])\n",
    "C_ppi_t0 = float(data.loc[t0_ts, \"C_scrap_ppi\"])\n",
    "P_paths_eur = P_paths_ppi.apply(lambda col: anchor_index_to_real(col.values, P_ppi_t0, P0_real), axis=0)\n",
    "C_paths_eur = C_paths_ppi.apply(lambda col: anchor_index_to_real(col.values, C_ppi_t0, C0_real), axis=0)\n",
    "\n",
    "P_paths_eur = pd.DataFrame(P_paths_eur.values, index=dates, columns=P_paths_ppi.columns)\n",
    "C_paths_eur = pd.DataFrame(C_paths_eur.values, index=dates, columns=C_paths_ppi.columns)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Demand: keep as index OR scale to tons using an anchor\n",
    "# -----------------------------\n",
    "if use_demand_scaling_to_tons:\n",
    "    D_idx_t0 = float(data.loc[t0_ts, \"D_steel_ip\"])\n",
    "    D_paths_tons = D0_real * (D_paths_idx / D_idx_t0)\n",
    "    D_final = D_paths_tons\n",
    "else:\n",
    "    D_final = D_paths_idx  # index units (fine; you can later scale)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Export scenarios in long form for the SP\n",
    "# -----------------------------\n",
    "def wide_to_long(wide: pd.DataFrame, value_name: str) -> pd.DataFrame:\n",
    "    out = wide.stack().rename(value_name).reset_index()\n",
    "    out = out.rename(columns={\"level_0\": \"Date\", \"level_1\": \"Scenario\"})\n",
    "    return out\n",
    "\n",
    "scen_D = wide_to_long(D_final, cols[0])\n",
    "scen_P = wide_to_long(P_paths_eur, cols[1])\n",
    "scen_C = wide_to_long(C_paths_eur, cols[2])\n",
    "\n",
    "scenarios = scen_D.merge(scen_P, on=[\"Date\", \"Scenario\"]).merge(scen_C, on=[\"Date\", \"Scenario\"])\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83083abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create comprehensive scenario projection plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Number of scenarios to plot (for clarity, plot subset)\n",
    "n_plot = min(50, N_SCENARIOS)\n",
    "\n",
    "# Generate date range for plotting\n",
    "start_date = (data.index.max() + pd.offsets.MonthBegin(1)).normalize()\n",
    "future_dates = pd.date_range(start=start_date, periods=HORIZON_MONTHS, freq=\"MS\")\n",
    "\n",
    "# Combine historical and future dates for context\n",
    "hist_months = 32  # Show last 32 months of history\n",
    "hist_dates = data.index[-hist_months:]\n",
    "\n",
    "# Plot 1: Demand Index Scenarios\n",
    "ax = axes[0, 0]\n",
    "# Historical data\n",
    "ax.plot(hist_dates, data.loc[hist_dates, \"D_steel_ip\"], 'k-', linewidth=2, label='Historical')\n",
    "# Future scenarios\n",
    "for s in range(n_plot):\n",
    "    ax.plot(future_dates, D_paths_idx.iloc[:, s], alpha=0.3, linewidth=0.8, color='steelblue')\n",
    "# Mean projection\n",
    "ax.plot(future_dates, D_paths_idx.mean(axis=1), 'r-', linewidth=2, label='Mean Projection')\n",
    "# Confidence bands (10th-90th percentile)\n",
    "ax.fill_between(future_dates, \n",
    "                D_paths_idx.quantile(0.1, axis=1), \n",
    "                D_paths_idx.quantile(0.9, axis=1),\n",
    "                alpha=0.2, color='red', label='10th-90th Percentile')\n",
    "ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.set_title('Demand Index Projection\\n(Industrial Production)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Index (1982=100)', fontsize=10)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Price PPI Scenarios\n",
    "ax = axes[0, 1]\n",
    "ax.plot(hist_dates, data.loc[hist_dates, \"P_steel_ppi\"], 'k-', linewidth=2, label='Historical')\n",
    "for s in range(n_plot):\n",
    "    ax.plot(future_dates, P_paths_ppi.iloc[:, s], alpha=0.3, linewidth=0.8, color='green')\n",
    "ax.plot(future_dates, P_paths_ppi.mean(axis=1), 'r-', linewidth=2, label='Mean Projection')\n",
    "ax.fill_between(future_dates, \n",
    "                P_paths_ppi.quantile(0.1, axis=1), \n",
    "                P_paths_ppi.quantile(0.9, axis=1),\n",
    "                alpha=0.2, color='red', label='10th-90th Percentile')\n",
    "ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.set_title('Steel Price PPI Projection', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('PPI Index (1982=100)', fontsize=10)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Scrap Cost PPI Scenarios\n",
    "ax = axes[0, 2]\n",
    "ax.plot(hist_dates, data.loc[hist_dates, \"C_scrap_ppi\"], 'k-', linewidth=2, label='Historical')\n",
    "for s in range(n_plot):\n",
    "    ax.plot(future_dates, C_paths_ppi.iloc[:, s], alpha=0.3, linewidth=0.8, color='orange')\n",
    "ax.plot(future_dates, C_paths_ppi.mean(axis=1), 'r-', linewidth=2, label='Mean Projection')\n",
    "ax.fill_between(future_dates, \n",
    "                C_paths_ppi.quantile(0.1, axis=1), \n",
    "                C_paths_ppi.quantile(0.9, axis=1),\n",
    "                alpha=0.2, color='red', label='10th-90th Percentile')\n",
    "ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.set_title('Scrap Cost PPI Projection', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('PPI Index (1982=100)', fontsize=10)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- ROW 2: Real Values (€/ton) ---\n",
    "\n",
    "# Plot 4: Demand in Tons (if scaled)\n",
    "ax = axes[1, 0]\n",
    "if use_demand_scaling_to_tons:\n",
    "    # Show historical scaled demand if available\n",
    "    hist_demand_tons = D0_real * (data.loc[hist_dates, \"D_steel_ip\"] / D_idx_t0)\n",
    "    ax.plot(hist_dates, hist_demand_tons, 'k-', linewidth=2, label='Historical')\n",
    "    \n",
    "    for s in range(n_plot):\n",
    "        ax.plot(future_dates, D_final.iloc[:, s], alpha=0.3, linewidth=0.8, color='steelblue')\n",
    "    ax.plot(future_dates, D_final.mean(axis=1), 'r-', linewidth=2, label='Mean Projection')\n",
    "    ax.fill_between(future_dates, \n",
    "                    D_final.quantile(0.1, axis=1), \n",
    "                    D_final.quantile(0.9, axis=1),\n",
    "                    alpha=0.2, color='red', label='10th-90th Percentile')\n",
    "    ax.set_ylabel('Demand (tons/month)', fontsize=10)\n",
    "    ax.set_title('Demand Volume Projection', fontsize=12, fontweight='bold')\n",
    "else:\n",
    "    # Just show index version again with note\n",
    "    ax.plot(hist_dates, data.loc[hist_dates, \"D_steel_ip\"], 'k-', linewidth=2, label='Historical')\n",
    "    for s in range(n_plot):\n",
    "        ax.plot(future_dates, D_final.iloc[:, s], alpha=0.3, linewidth=0.8, color='steelblue')\n",
    "    ax.plot(future_dates, D_final.mean(axis=1), 'r-', linewidth=2, label='Mean Projection')\n",
    "    ax.set_ylabel('Index (1982=100)', fontsize=10)\n",
    "    ax.set_title('Demand Index Projection\\n(Set use_demand_scaling_to_tons=True for tons)', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Steel Price in €/ton\n",
    "ax = axes[1, 1]\n",
    "# Historical prices (anchored)\n",
    "hist_price_eur = P0_real * (data.loc[hist_dates, \"P_steel_ppi\"] / P_ppi_t0)\n",
    "ax.plot(hist_dates, hist_price_eur, 'k-', linewidth=2, label='Historical')\n",
    "\n",
    "for s in range(n_plot):\n",
    "    ax.plot(future_dates, P_paths_eur.iloc[:, s], alpha=0.3, linewidth=0.8, color='green')\n",
    "ax.plot(future_dates, P_paths_eur.mean(axis=1), 'r-', linewidth=2, label='Mean Projection')\n",
    "ax.fill_between(future_dates, \n",
    "                P_paths_eur.quantile(0.1, axis=1), \n",
    "                P_paths_eur.quantile(0.9, axis=1),\n",
    "                alpha=0.2, color='red', label='10th-90th Percentile')\n",
    "ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.set_title('Steel Price Projection (Real)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Price (€/ton)', fontsize=10)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Scrap Cost in €/ton\n",
    "ax = axes[1, 2]\n",
    "hist_cost_eur = C0_real * (data.loc[hist_dates, \"C_scrap_ppi\"] / C_ppi_t0)\n",
    "ax.plot(hist_dates, hist_cost_eur, 'k-', linewidth=2, label='Historical')\n",
    "\n",
    "for s in range(n_plot):\n",
    "    ax.plot(future_dates, C_paths_eur.iloc[:, s], alpha=0.3, linewidth=0.8, color='orange')\n",
    "ax.plot(future_dates, C_paths_eur.mean(axis=1), 'r-', linewidth=2, label='Mean Projection')\n",
    "ax.fill_between(future_dates, \n",
    "                C_paths_eur.quantile(0.1, axis=1), \n",
    "                C_paths_eur.quantile(0.9, axis=1),\n",
    "                alpha=0.2, color='red', label='10th-90th Percentile')\n",
    "ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax.set_title('Scrap Cost Projection (Real)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Cost (€/ton)', fontsize=10)\n",
    "ax.legend(fontsize=8)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Format all x-axes\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('Date', fontsize=10)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCENARIO PROJECTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Projection Period: {future_dates[0].strftime('%Y-%m')} to {future_dates[-1].strftime('%Y-%m')}\")\n",
    "print(f\"Number of Scenarios: {N_SCENARIOS}\")\n",
    "print(f\"Horizon: {HORIZON_MONTHS} months\")\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "\n",
    "for var_name, paths, unit in [\n",
    "    (\"Demand Index\", D_paths_idx, \"index\"),\n",
    "    (\"Steel Price PPI\", P_paths_ppi, \"index\"),\n",
    "    (\"Scrap Cost PPI\", C_paths_ppi, \"index\"),\n",
    "    (\"Steel Price\", P_paths_eur, \"€/ton\"),\n",
    "    (\"Scrap Cost\", C_paths_eur, \"€/ton\")\n",
    "]:\n",
    "    mean_val = paths.mean().mean()\n",
    "    std_val = paths.std().mean()\n",
    "    q10 = paths.quantile(0.1, axis=1).mean()\n",
    "    q90 = paths.quantile(0.9, axis=1).mean()\n",
    "    \n",
    "    print(f\"{var_name:20s}: {mean_val:8.2f} ± {std_val:6.2f} {unit}\")\n",
    "    print(f\"{'':20s}  [10th: {q10:7.2f}, 90th: {q90:7.2f}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df084b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_ret: (S, T, k)\n",
    "sim_df = pd.DataFrame(\n",
    "    sim_ret.reshape(-1, sim_ret.shape[2]),\n",
    "    columns=df_ret.columns\n",
    ")\n",
    "\n",
    "qs = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "for ax, col in zip(axes, df_ret.columns):\n",
    "    hq = df_ret[col].quantile(qs).values\n",
    "    sq = sim_df[col].quantile(qs).values\n",
    "\n",
    "    ax.plot(hq, sq, marker=\".\", linestyle=\"none\")\n",
    "    mn = min(hq.min(), sq.min())\n",
    "    mx = max(hq.max(), sq.max())\n",
    "    ax.plot([mn, mx], [mn, mx], linewidth=1)\n",
    "\n",
    "    ax.set_title(f\"QQ (Δlog): {col}\")\n",
    "    ax.set_xlabel(\"Historical Δlog quantiles\")\n",
    "    ax.set_ylabel(\"Simulated Δlog quantiles\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef2ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = 60\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "for ax, col in zip(axes, df_ret.columns):\n",
    "    ax.hist(df_ret[col].dropna(), bins=bins, density=True, alpha=0.5, label=\"Historical\")\n",
    "    ax.hist(sim_df[col].dropna(),  bins=bins, density=True, alpha=0.5, label=\"Simulated\")\n",
    "    ax.set_title(f\"Δlog distribution: {col}\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e16dcc",
   "metadata": {},
   "source": [
    "## Scenario Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1750cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn-extra\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "def build_feature_matrix(D: pd.DataFrame, P: pd.DataFrame, C: pd.DataFrame):\n",
    "    # stack paths into one vector per scenario\n",
    "    scen_names = D.columns\n",
    "    X = []\n",
    "    for s in scen_names:\n",
    "        v = np.concatenate([D[s].values, P[s].values, C[s].values])  # (3T,)\n",
    "        X.append(v)\n",
    "    return np.vstack(X), list(scen_names)\n",
    "\n",
    "def reduce_scenarios_kmedoids(D, P, C, K=30, stress_pct=0.0, seed=42):\n",
    "    \"\"\"\n",
    "    Reduce scenarios using K-Medoids clustering with optional stress scenario inclusion.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    D, P, C : pd.DataFrame\n",
    "        Scenario DataFrames for demand, price, and cost\n",
    "    K : int\n",
    "        Number of clusters (representative scenarios)\n",
    "    stress_pct : float\n",
    "        Fraction (0-1) of extreme tail scenarios to include for stress testing\n",
    "        E.g., 0.05 means 5% of K will be reserved for tail scenarios\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    D_red, P_red, C_red : pd.DataFrame\n",
    "        Reduced scenario DataFrames\n",
    "    w : pd.Series\n",
    "        Scenario weights (probabilities)\n",
    "    \"\"\"\n",
    "    X, scen_names = build_feature_matrix(D, P, C)\n",
    "\n",
    "    # Standardize so D/P/C blocks contribute comparably\n",
    "    scaler = StandardScaler()\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    # Calculate number of stress scenarios to include\n",
    "    n_stress = int(np.ceil(K * stress_pct))\n",
    "    n_regular = K - n_stress\n",
    "    \n",
    "    if n_stress > 0:\n",
    "        print(f\"Including {n_stress} stress scenarios ({stress_pct*100:.1f}%) out of {K} total\")\n",
    "        \n",
    "        # Step 1: Identify tail scenarios using extreme values\n",
    "        # Calculate severity score for each scenario (distance from median in standardized space)\n",
    "        median_scenario = np.median(Xs, axis=0)\n",
    "        distances = np.linalg.norm(Xs - median_scenario, axis=1)\n",
    "        \n",
    "        # Select most extreme scenarios (largest distances)\n",
    "        extreme_idx = np.argsort(distances)[-n_stress:]\n",
    "        extreme_scen = [scen_names[i] for i in extreme_idx]\n",
    "        \n",
    "        # Step 2: Cluster remaining scenarios\n",
    "        remaining_idx = np.setdiff1d(np.arange(len(scen_names)), extreme_idx)\n",
    "        Xs_regular = Xs[remaining_idx]\n",
    "        scen_names_regular = [scen_names[i] for i in remaining_idx]\n",
    "        \n",
    "        if n_regular > 0:\n",
    "            km = KMedoids(n_clusters=n_regular, random_state=seed, method=\"pam\")\n",
    "            labels_regular = km.fit_predict(Xs_regular)\n",
    "            \n",
    "            medoid_idx_regular = km.medoid_indices_\n",
    "            rep_scen_regular = [scen_names_regular[i] for i in medoid_idx_regular]\n",
    "            \n",
    "            # Calculate weights for regular scenarios\n",
    "            weights_regular = pd.Series(labels_regular).value_counts().sort_index()\n",
    "            total_regular_prob = 1.0 - stress_pct\n",
    "            prob_regular = (weights_regular / weights_regular.sum() * total_regular_prob).to_dict()\n",
    "        else:\n",
    "            rep_scen_regular = []\n",
    "            prob_regular = {}\n",
    "        \n",
    "        # Combine regular and stress scenarios\n",
    "        rep_scen = rep_scen_regular + extreme_scen\n",
    "        \n",
    "        # Assign equal weight to each stress scenario\n",
    "        stress_weight = stress_pct / n_stress if n_stress > 0 else 0.0\n",
    "        \n",
    "        # Build combined probability dictionary\n",
    "        rep_prob = {}\n",
    "        for j, scen in enumerate(rep_scen):\n",
    "            if scen in extreme_scen:\n",
    "                rep_prob[scen] = float(stress_weight)\n",
    "            else:\n",
    "                cluster_label = labels_regular[scen_names_regular.index(scen)]\n",
    "                rep_prob[scen] = float(prob_regular[cluster_label])\n",
    "    \n",
    "    else:\n",
    "        # Original behavior: no stress scenarios\n",
    "        km = KMedoids(n_clusters=K, random_state=seed, method=\"pam\")\n",
    "        labels = km.fit_predict(Xs)\n",
    "        \n",
    "        medoid_idx = km.medoid_indices_\n",
    "        rep_scen = [scen_names[i] for i in medoid_idx]\n",
    "        \n",
    "        weights = pd.Series(labels).value_counts().sort_index()\n",
    "        prob = (weights / weights.sum()).to_dict()\n",
    "        \n",
    "        rep_prob = {}\n",
    "        for j, scen in enumerate(rep_scen):\n",
    "            rep_prob[scen] = float(prob[j])\n",
    "\n",
    "    # return reduced scenario paths + weights\n",
    "    D_red = D[rep_scen].copy()\n",
    "    P_red = P[rep_scen].copy()\n",
    "    C_red = C[rep_scen].copy()\n",
    "\n",
    "    w = pd.Series(rep_prob, name=\"prob\").sort_index()\n",
    "    return D_red, P_red, C_red, w\n",
    "\n",
    "# Example usage:\n",
    "# stress_pct=0.0 → original behavior (no stress scenarios)\n",
    "# stress_pct=0.05 → 5% of scenarios are extreme tail scenarios for stress testing\n",
    "D_red, P_red, C_red, w = reduce_scenarios_kmedoids(\n",
    "    D_final, \n",
    "    P_paths_eur, \n",
    "    C_paths_eur, \n",
    "    K=1_000,\n",
    "    stress_pct=0.01)  # Include 1% stress scenarios\n",
    "\n",
    "print(f\"\\nTotal scenarios: {len(w)}\")\n",
    "print(f\"Total probability: {w.sum():.4f}\")\n",
    "print(f\"\\nWeight statistics:\")\n",
    "print(f\"  Min: {w.min():.4f}\")\n",
    "print(f\"  Max: {w.max():.4f}\")\n",
    "print(f\"  Mean: {w.mean():.4f}\")\n",
    "print(f\"  Std: {w.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ensure w is aligned with D_red.columns\n",
    "w = w.reindex(D_red.columns)\n",
    "\n",
    "# Function to compute weighted quantile\n",
    "def weighted_quantile(values, weights, q):\n",
    "    sorter = np.argsort(values)\n",
    "    values = values[sorter]\n",
    "    weights = weights[sorter]\n",
    "    cum_weights = np.cumsum(weights)\n",
    "    total_weight = cum_weights[-1]\n",
    "    idx = np.searchsorted(cum_weights, q * total_weight)\n",
    "    if idx == 0:\n",
    "        return values[0]\n",
    "    elif idx >= len(values):\n",
    "        return values[-1]\n",
    "    else:\n",
    "        return values[idx-1] + (values[idx] - values[idx-1]) * (q * total_weight - cum_weights[idx-1]) / weights[idx]\n",
    "\n",
    "# Generate date range for plotting\n",
    "start_date = (data.index.max() + pd.offsets.MonthBegin(1)).normalize()\n",
    "future_dates = pd.date_range(start=start_date, periods=HORIZON_MONTHS, freq=\"MS\")\n",
    "\n",
    "hist_months = 32\n",
    "hist_dates = data.index[-hist_months:]\n",
    "\n",
    "# Normalize weights for linewidth scaling (min 0.5, max 3)\n",
    "w_min, w_max = w.min(), w.max()\n",
    "def scale_weight(weight):\n",
    "    return 0.5 + 2.5 * (weight - w_min) / (w_max - w_min + 1e-9)\n",
    "\n",
    "# Create plots for reduced scenarios (1 row, 3 columns)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Helper function to plot scenarios\n",
    "def plot_reduced_scenarios(ax, hist_data, future_data, weights, color, title, ylabel):\n",
    "    # Historical\n",
    "    ax.plot(hist_dates, hist_data, 'k-', linewidth=2, label='Historical')\n",
    "    \n",
    "    # Plot each scenario with linewidth proportional to weight (no individual labels)\n",
    "    for s in future_data.columns:\n",
    "        lw = scale_weight(weights[s])\n",
    "        ax.plot(future_dates, future_data[s], alpha=0.5, linewidth=lw, color=color)\n",
    "    \n",
    "    # Weighted mean\n",
    "    weighted_mean = (future_data * weights).sum(axis=1)\n",
    "    ax.plot(future_dates, weighted_mean, 'r-', linewidth=2, label='Weighted Mean')\n",
    "    \n",
    "    # Weighted quantiles\n",
    "    q10 = [weighted_quantile(future_data.iloc[t, :].values, weights.values, 0.1) for t in range(len(future_dates))]\n",
    "    q90 = [weighted_quantile(future_data.iloc[t, :].values, weights.values, 0.9) for t in range(len(future_dates))]\n",
    "    ax.fill_between(future_dates, q10, q90, alpha=0.2, color='red', label='10th-90th Percentile')\n",
    "    \n",
    "    ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    ax.legend(fontsize=8, loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 1: Demand\n",
    "hist_demand = D0_real * (data.loc[hist_dates, \"D_steel_ip\"] / D_idx_t0) if use_demand_scaling_to_tons else data.loc[hist_dates, \"D_steel_ip\"]\n",
    "ylabel_d = 'Demand (tons/month)' if use_demand_scaling_to_tons else 'Index'\n",
    "plot_reduced_scenarios(axes[0], hist_demand, D_red, w, 'steelblue', 'Reduced Demand Projection', ylabel_d)\n",
    "\n",
    "# Plot 2: Steel Price\n",
    "hist_price = P0_real * (data.loc[hist_dates, \"P_steel_ppi\"] / P_ppi_t0)\n",
    "plot_reduced_scenarios(axes[1], hist_price, P_red, w, 'green', 'Reduced Steel Price Projection', 'Price (€/ton)')\n",
    "\n",
    "# Plot 3: Scrap Cost\n",
    "hist_cost = C0_real * (data.loc[hist_dates, \"C_scrap_ppi\"] / C_ppi_t0)\n",
    "plot_reduced_scenarios(axes[2], hist_cost, C_red, w, 'orange', 'Reduced Scrap Cost Projection', 'Cost (€/ton)')\n",
    "\n",
    "# Format x-axes\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Date', fontsize=10)\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REDUCED SCENARIO PROJECTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Number of Reduced Scenarios: {len(D_red.columns)}\")\n",
    "print(f\"Total Weight: {w.sum():.3f}\")\n",
    "print(f\"Weight range: [{w.min():.3f}, {w.max():.3f}]\")\n",
    "print(\"Line thickness represents scenario probability (thicker = higher weight)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686fb3d",
   "metadata": {},
   "source": [
    "# Stochastic Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39dc0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyomo.environ as pyo\n",
    "\n",
    "def build_sp_model(\n",
    "    scenarios: pd.DataFrame,\n",
    "    prob: pd.Series,\n",
    "    alpha: float,\n",
    "    c_var: float,\n",
    "    c_cap_base: float,\n",
    "    c_cap_flex: float,\n",
    "    delta_base: float,\n",
    "    delta_spot: float,\n",
    "    pen_unmet: float,\n",
    "    gamma_cap: float,\n",
    "    gamma_scrap: float,\n",
    "):\n",
    "    # -----------------------------\n",
    "    # Clean / align inputs\n",
    "    # -----------------------------\n",
    "    df = scenarios.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df[\"Scenario\"] = df[\"Scenario\"].astype(str)\n",
    "\n",
    "    prob = prob.copy()\n",
    "    prob.index = prob.index.astype(str)\n",
    "\n",
    "    # Validate probability mass\n",
    "    psum = float(prob.sum())\n",
    "    if abs(psum - 1.0) > 1e-6:\n",
    "        raise ValueError(f\"Scenario probabilities must sum to 1. Got {psum}\")\n",
    "\n",
    "    T = sorted(df[\"Date\"].unique())\n",
    "    S = sorted(df[\"Scenario\"].unique())\n",
    "\n",
    "    missing_probs = [s for s in S if s not in prob.index]\n",
    "    if missing_probs:\n",
    "        raise ValueError(f\"Missing probabilities for scenarios: {missing_probs[:10]}\")\n",
    "\n",
    "    # Build parameter dicts\n",
    "    # (t,s) -> value\n",
    "    D = {}\n",
    "    P = {}\n",
    "    C = {}\n",
    "\n",
    "    # Fast lookup via multi-index\n",
    "    df2 = df.set_index([\"Date\", \"Scenario\"]).sort_index()\n",
    "\n",
    "    for t in T:\n",
    "        for s in S:\n",
    "            try:\n",
    "                row = df2.loc[(t, s)]\n",
    "            except KeyError as e:\n",
    "                raise ValueError(f\"Missing (Date,Scenario)=({t},{s}) in scenarios_df\") from e\n",
    "\n",
    "            D[(t, s)] = float(row[\"D\"])\n",
    "            P[(t, s)] = float(row[\"P\"])\n",
    "            C[(t, s)] = float(row[\"C\"])\n",
    "\n",
    "    p = {s: float(prob.loc[s]) for s in S}\n",
    "\n",
    "    # -----------------------------\n",
    "    # Build model\n",
    "    # -----------------------------\n",
    "    m = pyo.ConcreteModel()\n",
    "\n",
    "    m.T = pyo.Set(initialize=T, ordered=True)\n",
    "    m.S = pyo.Set(initialize=S, ordered=True)\n",
    "\n",
    "    # Stage 1\n",
    "    m.Cap_base = pyo.Var(m.T, domain=pyo.NonNegativeReals)\n",
    "    m.Q_base   = pyo.Var(m.T, domain=pyo.NonNegativeReals)\n",
    "\n",
    "    # Stage 2 (recourse)\n",
    "    m.Cap_flex = pyo.Var(m.T, m.S, domain=pyo.NonNegativeReals)\n",
    "    m.x        = pyo.Var(m.T, m.S, domain=pyo.NonNegativeReals)  # production\n",
    "    m.y        = pyo.Var(m.T, m.S, domain=pyo.NonNegativeReals)  # sales\n",
    "    m.u        = pyo.Var(m.T, m.S, domain=pyo.NonNegativeReals)  # unmet demand\n",
    "    m.q_base   = pyo.Var(m.T, m.S, domain=pyo.NonNegativeReals)  # called from base\n",
    "    m.q_spot   = pyo.Var(m.T, m.S, domain=pyo.NonNegativeReals)  # spot bought\n",
    "\n",
    "    # -----------------------------\n",
    "    # Constraints\n",
    "    # -----------------------------\n",
    "    # Demand balance: y + u = D\n",
    "    def demand_bal(m, t, s):\n",
    "        return m.y[t, s] + m.u[t, s] == D[(t, s)]\n",
    "    m.DemandBal = pyo.Constraint(m.T, m.S, rule=demand_bal)\n",
    "\n",
    "    # No finished-goods inventory: y <= x\n",
    "    def no_fg_inv(m, t, s):\n",
    "        return m.y[t, s] <= m.x[t, s]\n",
    "    m.NoFGInv = pyo.Constraint(m.T, m.S, rule=no_fg_inv)\n",
    "\n",
    "    # Capacity: x <= Cap_base + Cap_flex\n",
    "    def cap_link(m, t, s):\n",
    "        return m.x[t, s] <= m.Cap_base[t] + m.Cap_flex[t, s]\n",
    "    m.CapLink = pyo.Constraint(m.T, m.S, rule=cap_link)\n",
    "\n",
    "    # Scrap consumption: alpha*x = q_base + q_spot\n",
    "    def scrap_bal(m, t, s):\n",
    "        return alpha * m.x[t, s] == m.q_base[t, s] + m.q_spot[t, s]\n",
    "    m.ScrapBal = pyo.Constraint(m.T, m.S, rule=scrap_bal)\n",
    "\n",
    "    # Base call limit: q_base <= Q_base\n",
    "    def base_call_limit(m, t, s):\n",
    "        return m.q_base[t, s] <= m.Q_base[t]\n",
    "    m.BaseCallLimit = pyo.Constraint(m.T, m.S, rule=base_call_limit)\n",
    "\n",
    "    # Recourse bound for capacity: Cap_flex <= gamma_cap * Cap_base\n",
    "    def flex_cap_bound(m, t, s):\n",
    "        return m.Cap_flex[t, s] <= gamma_cap * m.Cap_base[t]\n",
    "    m.FlexCapBound = pyo.Constraint(m.T, m.S, rule=flex_cap_bound)\n",
    "\n",
    "    # Recourse bound for scrap: q_spot <= gamma_scrap * Q_base\n",
    "    def spot_scrap_bound(m, t, s):\n",
    "        return m.q_spot[t, s] <= gamma_scrap * m.Q_base[t]\n",
    "    m.SpotScrapBound = pyo.Constraint(m.T, m.S, rule=spot_scrap_bound)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Objective: maximize expected profit\n",
    "    # -----------------------------\n",
    "    def obj_rule(m):\n",
    "        # Expected scenario profit\n",
    "        exp_profit = 0.0\n",
    "        for s in m.S:\n",
    "            scen_profit = 0.0\n",
    "            for t in m.T:\n",
    "                scen_profit += (\n",
    "                    P[(t, s)] * m.y[t, s]\n",
    "                    - C[(t, s)] * (m.q_base[t, s] + m.q_spot[t, s])\n",
    "                    - c_var * m.x[t, s]\n",
    "                    - c_cap_flex * m.Cap_flex[t, s]\n",
    "                    - delta_spot * m.q_spot[t, s]\n",
    "                    - pen_unmet * m.u[t, s]\n",
    "                )\n",
    "            exp_profit += p[s] * scen_profit\n",
    "\n",
    "        # Stage-1 costs (not scenario-weighted)\n",
    "        stage1_cost = sum(\n",
    "            c_cap_base * m.Cap_base[t] + delta_base * m.Q_base[t]\n",
    "            for t in m.T\n",
    "        )\n",
    "\n",
    "        return exp_profit - stage1_cost\n",
    "\n",
    "    m.Obj = pyo.Objective(rule=obj_rule, sense=pyo.maximize)\n",
    "\n",
    "    return m\n",
    "\n",
    "# -----------------------------\n",
    "# Solve helper\n",
    "# -----------------------------\n",
    "def solve_sp(model, solver_name=\"gurobi\", tee=True):\n",
    "    solver = pyo.SolverFactory(solver_name)\n",
    "    if not solver.available():\n",
    "        raise RuntimeError(f\"Solver '{solver_name}' is not available.\")\n",
    "    res = solver.solve(model, tee=tee)\n",
    "    return res\n",
    "\n",
    "# -----------------------------\n",
    "# Results extraction helper\n",
    "# -----------------------------\n",
    "def extract_results(model):\n",
    "    cap_base = pd.Series({t: pyo.value(model.Cap_base[t]) for t in model.T}).sort_index()\n",
    "    q_base   = pd.Series({t: pyo.value(model.Q_base[t]) for t in model.T}).sort_index()\n",
    "\n",
    "    # Expected totals across scenarios\n",
    "    # (weights are embedded in your prob input; if you want them here, pass prob separately)\n",
    "    return {\n",
    "        \"Cap_base\": cap_base,\n",
    "        \"Q_base\": q_base,\n",
    "    }\n",
    "\n",
    "scenarios_red = scenarios[scenarios[\"Scenario\"].isin(w.index.values)].copy()\n",
    "scenarios_red = scenarios_red.rename(columns={'D_steel_ip': 'D', 'P_steel_ppi': 'P', 'C_scrap_ppi': 'C'})\n",
    "\n",
    "m = build_sp_model(\n",
    "    scenarios=scenarios_red,\n",
    "    prob=w,\n",
    "    alpha=1.0, # scrap-to-product ratio\n",
    "    c_var=200.0, # variable production cost €/ton\n",
    "    c_cap_base=5.0, # base capacity cost €/ton-month\n",
    "    c_cap_flex=15.0, # flex capacity cost €/ton-month\n",
    "    delta_base=5.0, # cost to call base scrap €/ton\n",
    "    delta_spot=20.0, # cost to buy spot scrap €/ton\n",
    "    pen_unmet=200.0, # penalty for unmet demand €/ton\n",
    "    gamma_cap=0.3, # max flex capacity as fraction of base\n",
    "    gamma_scrap=1.0, # max spot scrap as fraction of base call\n",
    ")\n",
    "\n",
    "res = solve_sp(m, solver_name=\"highs\", tee=True)\n",
    "print(res.solver.termination_condition)\n",
    "out = extract_results(m)\n",
    "print(\"\\nOptimal Base Capacity (tons/month):\")\n",
    "print(out[\"Cap_base\"])\n",
    "print(\"\\nOptimal Base Call (tons/month):\")\n",
    "print(out[\"Q_base\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283be6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_profit_distribution(model, prob, confidence_levels=[0.05, 0.95]):\n",
    "    \"\"\"\n",
    "    Analyze profit distribution across scenarios and compute confidence intervals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : pyomo model (solved)\n",
    "    prob : pd.Series with scenario probabilities\n",
    "    confidence_levels : list of quantile levels for CI\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with profit statistics\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract scenario-specific profits\n",
    "    scenario_profits = []\n",
    "    scenario_names = []\n",
    "    weights = []\n",
    "    \n",
    "    for s in model.S:\n",
    "        profit_s = 0.0\n",
    "        for t in model.T:\n",
    "            # Get parameter values for this (t,s)\n",
    "            D_ts = sum(1 for t2, s2 in model.DemandBal if t2 == t and s2 == s)  # This won't work\n",
    "            # We need to rebuild the parameter dictionaries or store them\n",
    "    \n",
    "    # Since we need the original parameters, let's rebuild them\n",
    "    scenarios_red = scenarios[scenarios[\"Scenario\"].isin(prob.index.values)].copy()\n",
    "    scenarios_red = scenarios_red.rename(columns={'D_steel_ip': 'D', 'P_steel_ppi': 'P', 'C_scrap_ppi': 'C'})\n",
    "    \n",
    "    df = scenarios_red.copy()\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    df[\"Scenario\"] = df[\"Scenario\"].astype(str)\n",
    "    df2 = df.set_index([\"Date\", \"Scenario\"]).sort_index()\n",
    "    \n",
    "    T = sorted(df[\"Date\"].unique())\n",
    "    S = sorted(df[\"Scenario\"].unique())\n",
    "    \n",
    "    # Rebuild parameter dicts\n",
    "    D = {}\n",
    "    P = {}\n",
    "    C = {}\n",
    "    for t in T:\n",
    "        for s in S:\n",
    "            row = df2.loc[(t, s)]\n",
    "            D[(t, s)] = float(row[\"D\"])\n",
    "            P[(t, s)] = float(row[\"P\"])\n",
    "            C[(t, s)] = float(row[\"C\"])\n",
    "    \n",
    "    # Extract model parameters\n",
    "    alpha = 1.0\n",
    "    c_var = 200.0\n",
    "    c_cap_flex = 15.0\n",
    "    delta_spot = 20.0\n",
    "    pen_unmet = 200.0\n",
    "    \n",
    "    # Calculate profit for each scenario\n",
    "    for s in S:\n",
    "        profit_s = 0.0\n",
    "        for t in T:\n",
    "            profit_s += (\n",
    "                P[(t, s)] * pyo.value(model.y[t, s])\n",
    "                - C[(t, s)] * (pyo.value(model.q_base[t, s]) + pyo.value(model.q_spot[t, s]))\n",
    "                - c_var * pyo.value(model.x[t, s])\n",
    "                - c_cap_flex * pyo.value(model.Cap_flex[t, s])\n",
    "                - delta_spot * pyo.value(model.q_spot[t, s])\n",
    "                - pen_unmet * pyo.value(model.u[t, s])\n",
    "            )\n",
    "        \n",
    "        scenario_profits.append(profit_s)\n",
    "        scenario_names.append(s)\n",
    "        weights.append(float(prob.loc[s]))\n",
    "    \n",
    "    scenario_profits = np.array(scenario_profits)\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    # Calculate expected profit (weighted mean)\n",
    "    expected_profit = np.average(scenario_profits, weights=weights)\n",
    "    \n",
    "    # Calculate weighted percentiles for confidence intervals\n",
    "    def weighted_quantile(values, weights, q):\n",
    "        sorter = np.argsort(values)\n",
    "        values = values[sorter]\n",
    "        weights = weights[sorter]\n",
    "        cum_weights = np.cumsum(weights)\n",
    "        total_weight = cum_weights[-1]\n",
    "        idx = np.searchsorted(cum_weights, q * total_weight)\n",
    "        if idx == 0:\n",
    "            return values[0]\n",
    "        elif idx >= len(values):\n",
    "            return values[-1]\n",
    "        else:\n",
    "            return values[idx-1] + (values[idx] - values[idx-1]) * (q * total_weight - cum_weights[idx-1]) / weights[idx]\n",
    "    \n",
    "    # Calculate confidence intervals\n",
    "    ci_lower = weighted_quantile(scenario_profits, weights, confidence_levels[0])\n",
    "    ci_upper = weighted_quantile(scenario_profits, weights, confidence_levels[1])\n",
    "    \n",
    "    # Calculate additional statistics\n",
    "    profit_std = np.sqrt(np.average((scenario_profits - expected_profit)**2, weights=weights))\n",
    "    profit_min = np.min(scenario_profits)\n",
    "    profit_max = np.max(scenario_profits)\n",
    "    \n",
    "    return {\n",
    "        'expected_profit': expected_profit,\n",
    "        'profit_std': profit_std,\n",
    "        'profit_min': profit_min,\n",
    "        'profit_max': profit_max,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'confidence_level': f\"{(confidence_levels[1] - confidence_levels[0])*100:.0f}%\",\n",
    "        'scenario_profits': pd.Series(scenario_profits, index=scenario_names),\n",
    "        'scenario_weights': pd.Series(weights, index=scenario_names)\n",
    "    }\n",
    "\n",
    "# Analyze profit distribution\n",
    "profit_stats = analyze_profit_distribution(m, w)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROFIT DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Expected Profit: €{profit_stats['expected_profit']:,.0f}\")\n",
    "print(f\"Standard Deviation: €{profit_stats['profit_std']:,.0f}\")\n",
    "print(f\"Minimum Profit: €{profit_stats['profit_min']:,.0f}\")\n",
    "print(f\"Maximum Profit: €{profit_stats['profit_max']:,.0f}\")\n",
    "print(f\"\\n{profit_stats['confidence_level']} Confidence Interval:\")\n",
    "print(f\"  Lower bound: €{profit_stats['ci_lower']:,.0f}\")\n",
    "print(f\"  Upper bound: €{profit_stats['ci_upper']:,.0f}\")\n",
    "\n",
    "# Plot profit distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram of scenario profits\n",
    "scenario_profits = profit_stats['scenario_profits']\n",
    "weights = profit_stats['scenario_weights']\n",
    "\n",
    "ax1.hist(scenario_profits, bins=20, weights=weights, alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(profit_stats['expected_profit'], color='red', linestyle='--', linewidth=2, label='Expected Profit')\n",
    "ax1.axvline(profit_stats['ci_lower'], color='orange', linestyle='--', linewidth=1.5, label=f\"{profit_stats['confidence_level']} CI\")\n",
    "ax1.axvline(profit_stats['ci_upper'], color='orange', linestyle='--', linewidth=1.5)\n",
    "ax1.set_xlabel('Profit (€)')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title('Weighted Profit Distribution')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot: profit vs scenario weight\n",
    "ax2.scatter(weights, scenario_profits, alpha=0.7, s=50)\n",
    "ax2.axhline(profit_stats['expected_profit'], color='red', linestyle='--', linewidth=2, label='Expected Profit')\n",
    "ax2.axhline(profit_stats['ci_lower'], color='orange', linestyle='--', linewidth=1.5, label=f\"{profit_stats['confidence_level']} CI\")\n",
    "ax2.axhline(profit_stats['ci_upper'], color='orange', linestyle='--', linewidth=1.5)\n",
    "ax2.set_xlabel('Scenario Weight')\n",
    "ax2.set_ylabel('Profit (€)')\n",
    "ax2.set_title('Profit vs Scenario Probability')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show worst and best case scenarios\n",
    "print(f\"\\nWorst Case Scenario (ID: {scenario_profits.idxmin()}):\")\n",
    "print(f\"  Profit: €{scenario_profits.min():,.0f}\")\n",
    "print(f\"  Weight: {weights[scenario_profits.idxmin()]:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Case Scenario (ID: {scenario_profits.idxmax()}):\")\n",
    "print(f\"  Profit: €{scenario_profits.max():,.0f}\")\n",
    "print(f\"  Weight: {weights[scenario_profits.idxmax()]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f47b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Extract scenario profits from the analysis\n",
    "scenario_profits = profit_stats['scenario_profits']\n",
    "\n",
    "# Create a colormap for profits\n",
    "norm = Normalize(vmin=scenario_profits.min(), vmax=scenario_profits.max())\n",
    "cmap = cm.RdYlGn  # Red-Yellow-Green colormap (red=low profit, green=high profit)\n",
    "\n",
    "# Generate date range for plotting\n",
    "start_date = (data.index.max() + pd.offsets.MonthBegin(1)).normalize()\n",
    "future_dates = pd.date_range(start=start_date, periods=HORIZON_MONTHS, freq=\"MS\")\n",
    "\n",
    "hist_months = 60\n",
    "hist_dates = data.index[-hist_months:]\n",
    "\n",
    "# Create plots with profit-colored scenarios\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "def plot_profit_colored_scenarios(ax, hist_data, future_data, scenario_profits, title, ylabel):\n",
    "    # Historical data\n",
    "    ax.plot(hist_dates, hist_data, 'k-', linewidth=3, label='Historical', alpha=0.8)\n",
    "    \n",
    "    # Plot each scenario colored by profit\n",
    "    for s in future_data.columns:\n",
    "        if s in scenario_profits.index:\n",
    "            profit = scenario_profits[s]\n",
    "            color = cmap(norm(profit))\n",
    "            alpha = 0.6\n",
    "            linewidth = 1.5\n",
    "        else:\n",
    "            color = 'gray'\n",
    "            alpha = 0.3\n",
    "            linewidth = 0.5\n",
    "        \n",
    "        ax.plot(future_dates, future_data[s], color=color, alpha=alpha, linewidth=linewidth)\n",
    "    \n",
    "    # Add vertical line at transition\n",
    "    ax.axvline(x=data.index.max(), color='gray', linestyle='--', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 1: Demand colored by profit\n",
    "hist_demand = D0_real * (data.loc[hist_dates, \"D_steel_ip\"] / D_idx_t0) if use_demand_scaling_to_tons else data.loc[hist_dates, \"D_steel_ip\"]\n",
    "ylabel_d = 'Demand (tons/month)' if use_demand_scaling_to_tons else 'Index'\n",
    "plot_profit_colored_scenarios(\n",
    "    axes[0], hist_demand, D_red, scenario_profits,\n",
    "    'Demand Scenarios\\n(Colored by Profit)', ylabel_d\n",
    ")\n",
    "\n",
    "# Plot 2: Steel Price colored by profit\n",
    "hist_price = P0_real * (data.loc[hist_dates, \"P_steel_ppi\"] / P_ppi_t0)\n",
    "plot_profit_colored_scenarios(\n",
    "    axes[1], hist_price, P_red, scenario_profits,\n",
    "    'Steel Price Scenarios\\n(Colored by Profit)', 'Price (€/ton)'\n",
    ")\n",
    "\n",
    "# Plot 3: Scrap Cost colored by profit\n",
    "hist_cost = C0_real * (data.loc[hist_dates, \"C_scrap_ppi\"] / C_ppi_t0)\n",
    "plot_profit_colored_scenarios(\n",
    "    axes[2], hist_cost, C_red, scenario_profits,\n",
    "    'Scrap Cost Scenarios\\n(Colored by Profit)', 'Cost (€/ton)'\n",
    ")\n",
    "\n",
    "# Format x-axes\n",
    "for ax in axes:\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# Apply tight_layout first to position the plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Then add colorbar with manual positioning\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "# Use figure.add_axes to manually position the colorbar\n",
    "cbar_ax = fig.add_axes([0.15, 0, 0.7, 0.03])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\n",
    "cbar.set_label('Scenario Profit (€)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print insights about profit vs scenario characteristics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROFIT vs SCENARIO CHARACTERISTICS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze correlation between final period values and profits\n",
    "final_period_data = {}\n",
    "for s in scenario_profits.index:\n",
    "    if s in D_red.columns:\n",
    "        final_period_data[s] = {\n",
    "            'demand': D_red[s].iloc[-1],\n",
    "            'price': P_red[s].iloc[-1], \n",
    "            'cost': C_red[s].iloc[-1],\n",
    "            'profit': scenario_profits[s]\n",
    "        }\n",
    "\n",
    "final_df = pd.DataFrame(final_period_data).T\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = final_df.corr()['profit'].drop('profit')\n",
    "print(\"Correlation between final period values and total profit:\")\n",
    "for var, corr in correlations.items():\n",
    "    print(f\"  {var.capitalize():8s}: {corr:+.3f}\")\n",
    "\n",
    "# Show top and bottom scenarios\n",
    "print(f\"\\nTop 3 Most Profitable Scenarios:\")\n",
    "top_scenarios = scenario_profits.nlargest(3)\n",
    "for i, (scen, profit) in enumerate(top_scenarios.items(), 1):\n",
    "    if scen in final_df.index:\n",
    "        row = final_df.loc[scen]\n",
    "        print(f\"  {i}. Scenario {scen}: €{profit:,.0f}\")\n",
    "        print(f\"     Final values - Demand: {row['demand']:,.0f}, Price: €{row['price']:.0f}, Cost: €{row['cost']:.0f}\")\n",
    "\n",
    "print(f\"\\nTop 3 Least Profitable Scenarios:\")\n",
    "bottom_scenarios = scenario_profits.nsmallest(3)\n",
    "for i, (scen, profit) in enumerate(bottom_scenarios.items(), 1):\n",
    "    if scen in final_df.index:\n",
    "        row = final_df.loc[scen]\n",
    "        print(f\"  {i}. Scenario {scen}: €{profit:,.0f}\")\n",
    "        print(f\"     Final values - Demand: {row['demand']:,.0f}, Price: €{row['price']:.0f}, Cost: €{row['cost']:.0f}\")\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"- Green lines = High profit scenarios\")\n",
    "print(f\"- Red lines = Low profit scenarios\") \n",
    "print(f\"- Most profitable scenarios tend to have: {correlations.idxmax()} correlation\")\n",
    "print(f\"- Least profitable scenarios tend to have: {correlations.idxmin()} correlation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
